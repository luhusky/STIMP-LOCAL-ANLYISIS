import torch
import os
from torch.utils.data import DataLoader
import logging
import time
from tqdm import tqdm
from timm.utils import AverageMeter
import numpy as np
import argparse
import sys

# å¼ºåˆ¶æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆç¡®ä¿å¯¼å…¥æ— é”™ï¼‰
sys.path.insert(0, os.getcwd())
from dataset import HimawariHourlyDataset  # ä»datasetåŒ…å¯¼å…¥å°æ—¶æ•°æ®é›†ç±»
from utils import check_dir, masked_mae, masked_mse, seed_everything
from model.graphdiffusion import IAP_base  # å¯¼å…¥STIMPæ ¸å¿ƒæ¨¡å‹

# -------------------------- å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¸é¢„å¤„ç†è„šæœ¬ä¸€è‡´ï¼‰ --------------------------
parser = argparse.ArgumentParser(description='STIMPå°æ—¶æ•°æ®æ’å€¼æ¨¡å‹è®­ç»ƒï¼ˆä¸¥æ ¼éµå¾ªï¼šè®­ç»ƒæ’å€¼â†’ç”Ÿæˆæ’å€¼æ•°æ®â†’è®­ç»ƒé¢„æµ‹â†’ç”Ÿæˆé¢„æµ‹ï¼‰')

# å¿…éœ€å‚æ•°ï¼šé¢„å¤„ç†å.npyæ•°æ®æ ¹ç›®å½•
parser.add_argument('--raw_data_path', type=str, required=True, help='é¢„å¤„ç†å.npyæ•°æ®æ ¹ç›®å½•ï¼ˆå¦‚E:\\1workinANHUA\\4\\model_training\\hourly_samplesï¼‰')
# åŒºåŸŸä¸å°ºå¯¸å‚æ•°
parser.add_argument('--area', type=str, default='himawari', help='å›ºå®šä¸ºhimawari')
parser.add_argument('--height', type=int, default=128, help='ç©ºé—´é«˜åº¦ï¼ˆä¸é¢„å¤„ç†ä¸‹é‡‡æ ·å°ºå¯¸ä¸€è‡´ï¼‰')
parser.add_argument('--width', type=int, default=128, help='ç©ºé—´å®½åº¦ï¼ˆä¸é¢„å¤„ç†ä¸‹é‡‡æ ·å°ºå¯¸ä¸€è‡´ï¼‰')
# åºåˆ—é•¿åº¦å‚æ•°ï¼ˆå¿…é¡»ä¸é¢„å¤„ç†è„šæœ¬ä¸€è‡´ï¼‰
parser.add_argument('--in_len', type=int, default=12, help='è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆ=é¢„å¤„ç†SEQ_LENï¼‰')
parser.add_argument('--out_len', type=int, default=1, help='è¾“å‡ºåºåˆ—é•¿åº¦ï¼ˆ=é¢„å¤„ç†PRED_LENï¼‰')
# è®­ç»ƒå‚æ•°
parser.add_argument('--missing_ratio', type=float, default=0.1, help='ç¼ºå¤±ç‡ï¼ˆ0-1ï¼‰')
parser.add_argument('--epochs', type=int, default=500, help='è®­ç»ƒè½®æ¬¡')
parser.add_argument('--batch_size', type=int, default=1, help='æ‰¹æ¬¡å¤§å°ï¼ˆé«˜åˆ†è¾¨ç‡æ•°æ®å»ºè®®=1ï¼‰')
parser.add_argument('--lr', type=float, default=1e-3, help='å­¦ä¹ ç‡')
parser.add_argument('--wd', type=float, default=1e-4, help='æƒé‡è¡°å‡')
parser.add_argument('--test_freq', type=int, default=50, help='æ¯nè½®æµ‹è¯•ä¸€æ¬¡å¹¶ä¿å­˜æ¨¡å‹')
# æ¨¡å‹å‚æ•°ï¼ˆä¸åŸSTIMPä¸€è‡´ï¼‰
parser.add_argument('--embedding_size', type=int, default=32, help='åµŒå…¥ç»´åº¦')
parser.add_argument('--hidden_channels', type=int, default=32, help='éšè—å±‚ç»´åº¦')
parser.add_argument('--diffusion_embedding_size', type=int, default=64, help='æ‰©æ•£æ¨¡å‹åµŒå…¥ç»´åº¦')
parser.add_argument('--side_channels', type=int, default=1, help='è¾…åŠ©ç‰¹å¾é€šé“æ•°ï¼ˆSSTå•é€šé“ï¼‰')
parser.add_argument('--beta_start', type=float, default=0.0001, help='æ‰©æ•£betaèµ·å§‹å€¼')
parser.add_argument('--beta_end', type=float, default=0.2, help='æ‰©æ•£betaç»“æŸå€¼')
parser.add_argument('--num_steps', type=float, default=50, help='å»å™ªæ­¥æ•°')
parser.add_argument('--num_samples', type=int, default=10, help='é‡‡æ ·æ•°é‡')
parser.add_argument('--schedule', type=str, default='quad', help='å™ªå£°è°ƒåº¦ç±»å‹')
parser.add_argument('--target_strategy', type=str, default='random', help='æ©ç ç­–ç•¥ï¼ˆrandom/blockï¼‰')
parser.add_argument('--num_heads', type=int, default=8, help='è‡ªæ³¨æ„åŠ›å¤´æ•°')

if __name__ == '__main__':
    config = parser.parse_args()

    # è®­ç»ƒè¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼ŒæŒ‰å‚æ•°åŒºåˆ†ï¼‰
    base_dir = f"./tmp/imputation/{config.in_len}/{config.area}/STIMP_hourly_missing_{config.missing_ratio}/"
    device = torch.device("cuda:0" if torch.cuda.is_available() else torch.device("cpu"))
    check_dir(base_dir)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    seed_everything(1234)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯å¯å¤ç°

    # æ—¥å¿—é…ç½®ï¼ˆä¿å­˜è®­ç»ƒè¿‡ç¨‹ï¼‰
    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    log_file = os.path.join(base_dir, f'train_log_{timestamp}.log')
    logging.basicConfig(
        level=logging.INFO,
        filename=log_file,
        filemode='a',
        format='%(asctime)s - %(message)s'
    )
    print("="*80)
    print("STIMPå°æ—¶æ•°æ®æ’å€¼æ¨¡å‹è®­ç»ƒï¼ˆä¸¥æ ¼éµå¾ªä½ çš„æµç¨‹ï¼šè®­ç»ƒæ’å€¼â†’ç”Ÿæˆæ’å€¼æ•°æ®â†’è®­ç»ƒé¢„æµ‹â†’ç”Ÿæˆé¢„æµ‹ï¼‰")
    print("="*80)
    print("é…ç½®å‚æ•°ï¼š")
    for k, v in vars(config).items():
        print(f"  {k}: {v}")
    logging.info(f"é…ç½®å‚æ•°ï¼š{vars(config)}")

    # åŠ è½½å°æ—¶æ•°æ®æ•°æ®é›†ï¼ˆä»datasetåŒ…å¯¼å…¥ï¼Œæ— æŠ¥é”™ï¼‰
    print("\n" + "="*80)
    print("åŠ è½½æ•°æ®é›†...")
    train_dataset = HimawariHourlyDataset(config, mode="train")
    test_dataset = HimawariHourlyDataset(config, mode="test")
    print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼šè®­ç»ƒé›†{len(train_dataset)}æ ·æœ¬ï¼Œæµ‹è¯•é›†{len(test_dataset)}æ ·æœ¬")

    # æ•°æ®åŠ è½½å™¨ï¼ˆå•è¿›ç¨‹ï¼Œé¿å…å¤šè¿›ç¨‹å†²çªï¼‰
    train_dloader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=0,  # å•è¿›ç¨‹
        pin_memory=True  # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    )
    test_dloader = DataLoader(
        test_dataset,
        batch_size=config.batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    # åŠ è½½ç©ºé—´é‚»æ¥çŸ©é˜µï¼ˆé¢„å¤„ç†è„šæœ¬ç”Ÿæˆï¼‰
    print("\n" + "="*80)
    print("åŠ è½½ç©ºé—´é‚»æ¥çŸ©é˜µ...")
    adj_path = os.path.join(config.raw_data_path, "spatial_graph.npy")
    if not os.path.exists(adj_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°é‚»æ¥çŸ©é˜µï¼è¯·å…ˆè¿è¡Œé¢„å¤„ç†è„šæœ¬ï¼š{adj_path}")
    adj = np.load(adj_path)
    adj = torch.from_numpy(adj).float().to(device)
    # é‚»æ¥çŸ©é˜µä¸‹é‡‡æ ·ï¼ˆä¸æ•°æ®ç©ºé—´å°ºå¯¸åŒ¹é…ï¼‰
    n_nodes = config.height * config.width
    if adj.shape[0] != n_nodes:
        print(f"é‚»æ¥çŸ©é˜µä¸‹é‡‡æ ·ï¼š{adj.shape[0]} â†’ {n_nodes}")
        adj = torch.nn.functional.interpolate(
            adj.unsqueeze(0).unsqueeze(0),
            size=(n_nodes, n_nodes),
            mode="bilinear",
            align_corners=False
        ).squeeze(0).squeeze(0)
        adj = (adj > 0.5).float()  # äºŒå€¼åŒ–ï¼Œç¡®ä¿æ˜¯é‚»æ¥çŸ©é˜µ
    print(f"é‚»æ¥çŸ©é˜µåŠ è½½å®Œæˆï¼ˆå½¢çŠ¶ï¼š{adj.shape}ï¼‰")

    # æ•°æ®è¾¹ç•Œï¼ˆä¸é¢„å¤„ç†æ ‡å‡†åŒ–ä¸€è‡´ï¼‰
    low_bound = torch.from_numpy(train_dataset.min).float().to(device)
    high_bound = torch.from_numpy(train_dataset.max).float().to(device)
    print(f"æ•°æ®è¾¹ç•Œï¼šmin={low_bound.item():.2f}â„ƒï¼Œmax={high_bound.item():.2f}â„ƒ")

    # åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨
    print("\n" + "="*80)
    print("åˆå§‹åŒ–æ¨¡å‹...")
    model = IAP_base(config, low_bound, high_bound).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.wd)
    # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆ75%/90%è½®æ¬¡è¡°å‡ï¼‰
    p1 = int(0.75 * config.epochs)
    p2 = int(0.9 * config.epochs)
    optimizer_scheduler = torch.optim.lr_scheduler.MultiStepLR(
        optimizer,
        milestones=[p1, p2],
        gamma=0.1
    )
    print(f"æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆå‚æ•°æ€»æ•°ï¼š{sum(p.numel() for p in model.parameters()):,}ï¼‰")

    # è®­ç»ƒä¸»å¾ªç¯ï¼ˆæ’å€¼æ¨¡å‹è®­ç»ƒï¼Œä¸æ”¹å˜ä½ çš„æµç¨‹ï¼‰
    best_mae_sst = 100.0  # è®°å½•æœ€ä½³SSTæ’å€¼MAE
    print("\n" + "="*80)
    train_process = tqdm(range(1, config.epochs + 1), desc="è®­ç»ƒè¿›åº¦")
    for epoch in train_process:
        model.train()  # è®­ç»ƒæ¨¡å¼
        optimizer_scheduler.step(epoch)  # æ›´æ–°å­¦ä¹ ç‡
        data_time_m = AverageMeter()  # æ•°æ®åŠ è½½æ—¶é—´ç»Ÿè®¡
        losses_m = AverageMeter()  # è®­ç»ƒæŸå¤±ç»Ÿè®¡
        end = time.time()

        # éå†è®­ç»ƒæ•°æ®
        for train_step, (datas, data_ob_masks, data_gt_masks, labels, label_masks) in enumerate(train_dloader):
            # æ•°æ®è½¬GPU/CPU
            datas = datas.float().to(device)
            data_ob_masks = data_ob_masks.to(device)
            data_gt_masks = data_gt_masks.to(device)
            labels = labels.to(device)
            label_masks = label_masks.to(device)

            # è®¡ç®—è®­ç»ƒæŸå¤±ï¼ˆè°ƒç”¨STIMPæ¨¡å‹çš„trainstepæ–¹æ³•ï¼‰
            loss = model.trainstep(datas, data_ob_masks, adj, is_train=1)
            losses_m.update(loss.item(), datas.size(0))  # ç´¯è®¡æŸå¤±
            data_time_m.update(time.time() - end)  # ç´¯è®¡æ•°æ®åŠ è½½æ—¶é—´

            # åå‘ä¼ æ’­+æ¢¯åº¦è£å‰ª
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=1.0)  # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            optimizer.step()
            torch.cuda.synchronize()  # åŒæ­¥GPU
            end = time.time()

        # æ‰“å°è®­ç»ƒæ—¥å¿—
        log_str = f"Epoch {epoch:3d} | è®­ç»ƒæŸå¤±: {losses_m.avg:.4f} | æ•°æ®åŠ è½½æ—¶é—´: {data_time_m.avg:.4f}s"
        train_process.set_description(log_str)
        logging.info(log_str)

        # æµ‹è¯•ä¸ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆæ¯test_freqè½®ï¼‰
        if epoch % config.test_freq == 0 and epoch != 0:
            model.eval()  # è¯„ä¼°æ¨¡å¼
            sst_mae_list, sst_mse_list = [], []
            with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜
                for test_step, (datas, data_ob_masks, data_gt_masks, labels, label_masks) in enumerate(test_dloader):
                    # æ•°æ®è½¬è®¾å¤‡
                    datas = datas.float().to(device)
                    data_ob_masks = data_ob_masks.to(device)
                    data_gt_masks = data_gt_masks.to(device)
                    labels = labels.to(device)
                    label_masks = label_masks.to(device)

                    # æ¨¡å‹æ’è¡¥ï¼ˆç”Ÿæˆå®Œæ•´æ•°æ®ï¼‰
                    imputed_data = model.impute(datas, data_gt_masks, adj, config.num_samples)
                    imputed_data = imputed_data.median(dim=1).values  # å–ä¸­ä½æ•°ï¼Œç¨³å®šç»“æœ

                    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆä»…åœ¨ç¼ºå¤±åŒºåŸŸï¼‰
                    mask = (data_ob_masks - data_gt_masks).cpu()  # 1=ç¼ºå¤±åŒºåŸŸï¼ˆéœ€è¦è¯„ä¼°ï¼‰
                    sst_mae = masked_mae(imputed_data[:, :, 0].cpu(), datas[:, :, 0].cpu(), mask[:, :, 0])
                    sst_mse = masked_mse(imputed_data[:, :, 0].cpu(), datas[:, :, 0].cpu(), mask[:, :, 0])
                    sst_mae_list.append(sst_mae)
                    sst_mse_list.append(sst_mse)

            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            sst_mae = torch.stack(sst_mae_list).mean()
            sst_mse = torch.stack(sst_mse_list).mean()
            test_log = f"æµ‹è¯•ç»“æœ | Epoch {epoch:3d} | SST MAE: {sst_mae:.4f} | SST MSE: {sst_mse:.4f}"
            print("\n" + "="*80)
            print(test_log)
            logging.info(test_log)

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰MAEæ’åºï¼‰
            if sst_mae < best_mae_sst:
                best_mae_sst = sst_mae
                model_path = os.path.join(base_dir, f'best_model_epoch_{epoch}_mae_{sst_mae:.4f}.pt')
                torch.save(model, model_path)
                logging.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼š{model_path}ï¼ˆMAE: {best_mae_sst:.4f}ï¼‰")
                print(f"ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°ï¼š{model_path}")
            print("="*80 + "\n")

    # è®­ç»ƒå®Œæˆ
    print("\n" + "="*80)
    print("ğŸ‰ STIMPå°æ—¶æ•°æ®æ’å€¼æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ’å€¼MAEï¼š{best_mae_sst:.4f}")
    print(f"æœ€ä½³æ¨¡å‹ä½ç½®ï¼š{os.path.join(base_dir, 'best_model_*.pt')}")
    print("ä¸‹ä¸€æ­¥ï¼šä½¿ç”¨è¯¥æ¨¡å‹ç”Ÿæˆæ’å€¼æ•°æ®ï¼ˆå®Œæ•´æ— ç¼ºå¤±ï¼‰ï¼Œè¿›å…¥ä½ çš„'ç”Ÿæˆæ’å€¼æ•°æ®â†’è®­ç»ƒé¢„æµ‹â†’ç”Ÿæˆé¢„æµ‹'æµç¨‹")
    print("="*80)
    logging.info(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³MAEï¼š{best_mae_sst:.4f}")